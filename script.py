import os
import json
import cv2
import uuid
import base64
import numpy as np
import concurrent.futures
import hashlib
import argparse
from tqdm import tqdm
from yt_dlp import YoutubeDL
from PIL import Image
from openai import OpenAI
from google import genai
from google.genai import types
from anthropic import Anthropic
from dotenv import load_dotenv
import sys 

load_dotenv()

# =========================
# ê¸°ë³¸ ì„¤ì •
# =========================

DATA_ROOT = "playground/data"
FAKE_DIR = os.path.join(DATA_ROOT, "fake")
REAL_DIR = os.path.join(DATA_ROOT, "real")

# JSONL(append)ë¡œ ì €ì¥: ì¤‘ê°„ì— êº¼ì ¸ë„ ëˆ„ì  ë³´ì¡´
TRAIN_JSONL = os.path.join(DATA_ROOT, "train.jsonl")
TEST_JSONL = os.path.join(DATA_ROOT, "test.jsonl")

# ì§„í–‰ìƒíƒœ ì²´í¬í¬ì¸íŠ¸
PROGRESS_JSON = os.path.join(DATA_ROOT, "progress.json")

# í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ 1ê°œ ì˜ìƒë§Œ ì²˜ë¦¬í•˜ë„ë¡ ì„¤ì • (í•„ìš”ì‹œ ìˆ˜ì •)
TEST_ONLY_ONE_VIDEO = False

NUM_FRAMES_PER_VIDEO = 20  # ì˜ìƒ í•˜ë‚˜ë‹¹ ì¶”ì¶œí•  í”„ë ˆì„ ìˆ˜

os.makedirs(FAKE_DIR, exist_ok=True)
os.makedirs(REAL_DIR, exist_ok=True)
os.makedirs(DATA_ROOT, exist_ok=True)

# API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
gemini_client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))
anthropic_client = Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))

# =========================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# =========================

def encode_image_to_base64(image_path: str) -> str:
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")

def append_jsonl(path: str, obj: dict) -> None:
    """í•œ ì¤„ì— í•œ JSON ê°ì²´ë¥¼ append. í¬ë˜ì‹œ ë³µì›ì— ê°€ì¥ ì•ˆì „."""
    with open(path, "a", encoding="utf-8") as f:
        f.write(json.dumps(obj, ensure_ascii=False) + "\n")

def load_progress() -> dict:
    if os.path.exists(PROGRESS_JSON):
        try:
            with open(PROGRESS_JSON, "r", encoding="utf-8") as f:
                data = json.load(f)
            if isinstance(data, dict) and "done_urls" in data and isinstance(data["done_urls"], list):
                return data
        except Exception:
            pass
    return {"done_urls": []}

def save_progress(progress: dict) -> None:
    """atomic writeë¡œ progress.json ê¹¨ì§ ë°©ì§€"""
    tmp = PROGRESS_JSON + ".tmp"
    with open(tmp, "w", encoding="utf-8") as f:
        json.dump(progress, f, indent=2, ensure_ascii=False)
    os.replace(tmp, PROGRESS_JSON)

def url_to_key(url: str) -> str:
    """URLì„ ì§§ì€ ê³ ì • í‚¤ë¡œ ë³€í™˜ (íŒŒì¼ëª…/ì‹ë³„ììš©)"""
    return hashlib.sha1(url.encode("utf-8")).hexdigest()[:16]

def remove_samples_for_url(jsonl_path: str, target_url: str) -> int:
    """jsonlì—ì„œ íŠ¹ì • URLë¡œ ìƒì„±ëœ ìƒ˜í”Œë§Œ ì œê±°"""
    if not os.path.exists(jsonl_path):
        return 0
    tmp = jsonl_path + ".tmp"
    removed = 0
    with open(jsonl_path, "r", encoding="utf-8") as fin, open(tmp, "w", encoding="utf-8") as fout:
        for line in fin:
            line = line.strip()
            if not line:
                continue
            try:
                obj = json.loads(line)
            except Exception:
                # ê¹¨ì§„ ë¼ì¸ì€ ë²„ë¦¼
                continue
            if obj.get("source_url") == target_url:
                removed += 1
                continue
            fout.write(json.dumps(obj, ensure_ascii=False) + "\n")
    os.replace(tmp, jsonl_path)
    return removed

def collect_image_paths_for_url(train_jsonl: str, test_jsonl: str, target_url: str) -> list[str]:
    """íŠ¹ì • URL ìƒ˜í”Œë“¤ì´ ì°¸ì¡°í•˜ëŠ” ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œë“¤ì„ ìˆ˜ì§‘ (ì‚­ì œìš©)"""
    paths = []
    for p in [train_jsonl, test_jsonl]:
        if not os.path.exists(p):
            continue
        with open(p, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    obj = json.loads(line)
                except Exception:
                    continue
                if obj.get("source_url") == target_url:
                    rel = obj.get("image")
                    if rel:
                        paths.append(os.path.join(DATA_ROOT, rel))
    # ì¤‘ë³µ ì œê±°
    return sorted(set(paths))

def delete_images(paths: list[str]) -> int:
    deleted = 0
    for p in paths:
        if os.path.exists(p):
            try:
                os.remove(p)
                deleted += 1
            except Exception:
                pass
    return deleted

def reset_url_state(target_url: str) -> None:
    """íŠ¹ì • URLì˜ ë°ì´í„°/ì§„í–‰ìƒíƒœë¥¼ ì œê±°í•´ì„œ ê·¸ URLë¶€í„° ë‹¤ì‹œ ëŒë¦´ ìˆ˜ ìˆê²Œ í•¨"""
    print(f"\n[RESET] Target URL: {target_url}")

    # 1) progress.jsonì—ì„œ done ì œê±°
    progress = load_progress()
    before = len(progress.get("done_urls", []))
    progress["done_urls"] = [u for u in progress.get("done_urls", []) if u != target_url]
    after = len(progress["done_urls"])
    save_progress(progress)
    print(f"[RESET] progress.json updated: done_urls {before} -> {after}")

    # 2) JSONLì—ì„œ í•´ë‹¹ URL ìƒ˜í”Œì´ ì°¸ì¡°í•˜ëŠ” ì´ë¯¸ì§€ ë¨¼ì € ì‚­ì œ
    img_paths = collect_image_paths_for_url(TRAIN_JSONL, TEST_JSONL, target_url)
    deleted_imgs = delete_images(img_paths)
    print(f"[RESET] deleted images: {deleted_imgs}")

    # 3) JSONLì—ì„œ í•´ë‹¹ URL ìƒ˜í”Œ ì œê±°
    removed_train = remove_samples_for_url(TRAIN_JSONL, target_url)
    removed_test = remove_samples_for_url(TEST_JSONL, target_url)
    print(f"[RESET] removed samples: train={removed_train}, test={removed_test}")

# =========================
# 1. ìœ íŠœë¸Œ ì˜ìƒ ë‹¤ìš´ë¡œë“œ
# =========================

def download_video(url: str, save_path: str) -> None:
    ydl_opts = {
        "outtmpl": save_path,
        "format": "bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best",
        "quiet": True,
        "no_warnings": True,
    }
    with YoutubeDL(ydl_opts) as ydl:
        ydl.download([url])

# =========================
# 2. í”„ë ˆì„ ì¶”ì¶œ (ê³ ì •ëœ ê°œìˆ˜)
# =========================

def extract_frames(video_path: str, label_dir: str, video_key: str, num_frames: int = 20) -> list[str]:
    """
    âœ… í”„ë ˆì„ íŒŒì¼ëª…ì„ ê²°ì •ì ìœ¼ë¡œ ìƒì„±:
    {video_key}_{frameIdx}.png
    -> ì¬ì‹¤í–‰í•´ë„ ê°™ì€ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥ë˜ì–´ ì¶”ì /ë¦¬ì…‹ì´ ì‰¬ì›€
    """
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"Error: Could not open video {video_path}")
        return []

    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    if total_frames <= 0:
        print(f"Error: Video {video_path} has no frames.")
        cap.release()
        return []

    frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)

    saved = []
    for i, idx in enumerate(frame_indices):
        cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))
        ret, frame = cap.read()
        if not ret:
            continue

        img_name = f"{video_key}_{i:03d}.png"
        img_path = os.path.join(label_dir, img_name)
        cv2.imwrite(img_path, frame)
        saved.append(img_path)

    cap.release()
    return saved

# =========================
# 3. ê°œë³„ LLM ë¶„ì„ í•¨ìˆ˜
# =========================

def _base_prompt(label: int) -> str:
    return (
        f"Analyze this image. It is labeled as {'fake (deepfake)' if label == 0 else 'real'}. "
        f"Explain why it is {'fake' if label == 0 else 'real'} based on lighting, texture, shadows, and consistency. "
        "Keep the response under 300 chars."
    )

def get_openai_analysis(image_path: str, label: int) -> str:
    base64_image = encode_image_to_base64(image_path)
    prompt = _base_prompt(label)

    response = openai_client.responses.create(
        model="gpt-5-mini-2025-08-07",
        input=[
            {
                "role": "user",
                "content": [
                    {"type": "input_text", "text": prompt},
                    {"type": "input_image", "image_url": f"data:image/png;base64,{base64_image}"},
                ],
            }
        ],
    )
    return response.output_text

def get_gemini_analysis(image_path: str, label: int) -> str:
    prompt = _base_prompt(label)
    with open(image_path, "rb") as f:
        img_data = f.read()

    response = gemini_client.models.generate_content(
        model="gemini-2.5-flash",
        contents=[prompt, types.Part.from_bytes(data=img_data, mime_type="image/png")],
    )
    return response.text

MAX_IMAGE_BYTES = 5 * 1024 * 1024  # 5MB


def get_anthropic_analysis(image_path: str, label: int) -> str | None:
    # 1) ì¸ì½”ë”©(ë„¤ê°€ ì‹¤ì œë¡œ ìš”ì²­ì— ë„£ëŠ” ë°ì´í„°)
    base64_image = encode_image_to_base64(image_path)

    # 2) Anthropic ê¸°ì¤€ìœ¼ë¡œ "ì‹¤ì œ ì´ë¯¸ì§€ ë°”ì´íŠ¸" ì²´í¬ (ì¤‘ìš”!)
    try:
        image_bytes = base64.b64decode(base64_image, validate=True)
    except Exception as e:
        print(f"[SKIP] Anthropic invalid base64 for {image_path}: {e}")
        return None

    if len(image_bytes) > MAX_IMAGE_BYTES:
        print(f"[SKIP] Anthropic image too large AFTER encoding: {len(image_bytes)} bytes")
        return None

    prompt = _base_prompt(label)

    try:
        response = anthropic_client.messages.create(
            model="claude-haiku-4-5-20251001",
            max_tokens=150,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image",
                            "source": {
                                "type": "base64",
                                "media_type": "image/png",
                                "data": base64_image,
                            },
                        },
                        {"type": "text", "text": prompt},
                    ],
                }
            ],
        )
        return response.content[0].text
    except Exception as e:
        # í˜¹ì‹œë¼ë„ ë‚¨ëŠ” ì¼€ì´ìŠ¤ëŠ” ì•ˆì „í•˜ê²Œ ìŠ¤í‚µ
        if "image exceeds 5 MB maximum" in str(e):
            print("[SKIP] Anthropic rejected image > 5MB")
            return None
        print(f"[SKIP] Anthropic error: {e}")
        return None

# =========================
# 4. ê²°ê³¼ ë³‘í•© (Expert Merger LLM)
# =========================

def merge_responses(responses: list[str], label: int) -> str:
    merger_prompt = f"""
You are an expert in AI-generated content analysis. Merge the following three model responses into
one unified answer. All responses agree on the imageâ€™s authenticity ({'fake' if label==0 else 'real'}). Prioritize explanations
mentioned by at least two models and omit points unique to a single model. Keep the response under 200 chars.
Follow these steps:
â€¢ Extract Common Ground: Identify overlapping details across all three responses.
â€¢ Filter Minority Claims: Discard observations mentioned by only one model unless critical.
â€¢ Structure Hierarchically: Group explanations by category for clarity.
â€¢ Maintain Original Format: Begin with â€œThis is a {'fake' if label==0 else 'real'} image.â€ then semicolon-separated evidence.
â€¢ Avoid Redundancy: Rephrase overlapping points.
â€¢ Ensure Logical Consistency: Discard nonsensical/contradictory reasoning.

Model Responses:
1. {responses[0]}
2. {responses[1]}
3. {responses[2]}
"""
    response = openai_client.responses.create(
        model="gpt-5-mini-2025-08-07",
        input=[{"role": "user", "content": [{"type": "input_text", "text": merger_prompt}]}],
    )
    return response.output_text.strip()

# =========================
# 5. JSON í¬ë§· ìƒì„±
# =========================

def build_sample(image_path: str, label: int, source_url: str, video_key: str) -> dict:
    # ğŸ”¹ ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆ ì½ê¸°
    try:
        img = Image.open(image_path)
        width, height = img.size
    except Exception as e:
        print(f"Error opening image {image_path}: {e}")
        width, height = 0, 0
    
    print(f"Analyzing image: {os.path.basename(image_path)} (Parallel)...")

    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
        future_openai = executor.submit(get_openai_analysis, image_path, label)
        future_gemini = executor.submit(get_gemini_analysis, image_path, label)
        future_anthropic = executor.submit(get_anthropic_analysis, image_path, label)

        try:
            openai_resp = future_openai.result()
            gemini_resp = future_gemini.result()
            anthropic_resp = future_anthropic.result()
        except Exception as e:
            # âœ… ì¦‰ì‹œ ì¤‘ë‹¨: ì›ì¸ ë¡œê·¸ ë‚¨ê¸°ê³  ì˜ˆì™¸ ì „íŒŒ
            print(f"\n[FATAL] API error during multi-LLM analysis: {e}", file=sys.stderr)
            raise  # <- ì¤‘ìš”: ì—¬ê¸°ì„œ ë©ˆì¶¤

    unified_explanation = merge_responses([openai_resp, gemini_resp, anthropic_resp], label)

    rel_image_path = os.path.relpath(image_path, DATA_ROOT)

    return {
        "image": rel_image_path,
        "label": label,
        "cate": "deepfake" if label == 0 else "real",
        "width": width,
        "height": height,
        "source_url": source_url,
        "video_key": video_key,
        "conversations": [
            {"from": "human", "value": "<image> Is this image real or fake?"},
            {"from": "gpt", "value": unified_explanation},
        ],
    }

# =========================
# 6. url.txt íŒŒì‹± ë¡œì§
# =========================

def parse_url_txt(file_path: str) -> list[dict]:
    videos = []
    current_label = None

    if not os.path.exists(file_path):
        return videos

    with open(file_path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue

            if line.startswith("fake"):
                current_label = 0
                continue
            elif line.startswith("real"):
                current_label = 1
                continue

            if current_label is not None and (line.startswith("http") or line.startswith("https")):
                videos.append({"url": line, "label": current_label})

    return videos

# =========================
# 7. ì „ì²´ íŒŒì´í”„ë¼ì¸ (ì²´í¬í¬ì¸íŠ¸ + JSONL append)
# =========================

def main(reset_url: str | None = None):
    if reset_url:
        reset_url_state(reset_url)

    video_list = parse_url_txt("url.txt")
    if not video_list:
        print("Error: No URLs found in url.txt or formatting is wrong.")
        return

    if TEST_ONLY_ONE_VIDEO:
        video_list = video_list[:1]
        print(f"Running TEST mode: Only processing {len(video_list)} video(s).")

    progress = load_progress()
    done = set(progress.get("done_urls", []))

    for video_info in tqdm(video_list, desc="Processing videos"):
        url = video_info["url"]
        label = video_info["label"]

        # ì´ë¯¸ ëë‚¸ URLì´ë©´ ìŠ¤í‚µ
        if url in done:
            print(f"\n[SKIP] Already processed: {url}")
            continue

        video_key = url_to_key(url)

        video_id = uuid.uuid4().hex
        video_path = f"{video_id}.mp4"

        print(f"\nDownloading: {url} (Label: {'fake' if label==0 else 'real'})")
        try:
            download_video(url, video_path)
        except Exception as e:
            print(f"Error downloading {url}: {e}")
            continue

        label_dir = FAKE_DIR if label == 0 else REAL_DIR

        print(f"Extracting {NUM_FRAMES_PER_VIDEO} frames...")
        frames = extract_frames(video_path, label_dir, video_key=video_key, num_frames=NUM_FRAMES_PER_VIDEO)

        if not frames:
            print(f"[WARN] No frames extracted for {url}")
            if os.path.exists(video_path):
                os.remove(video_path)
            continue

        # 15:5 split (20ê°œ ê¸°ì¤€)
        for i, img_path in enumerate(frames):
            sample = build_sample(img_path, label, source_url=url, video_key=video_key)
            if i < 15:
                append_jsonl(TRAIN_JSONL, sample)
            else:
                append_jsonl(TEST_JSONL, sample)

        # ì˜ìƒ íŒŒì¼ ì •ë¦¬
        if os.path.exists(video_path):
            os.remove(video_path)

        # ì—¬ê¸°ê¹Œì§€ ì˜¤ë©´ "ì´ URLì€ ì™„ë£Œ"ë¡œ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        done.add(url)
        progress["done_urls"] = sorted(done)
        save_progress(progress)
        print(f"[DONE] {url} saved to progress.")

    print("\nAll done.")
    print(f"- Train JSONL: {TRAIN_JSONL}")
    print(f"- Test  JSONL: {TEST_JSONL}")
    print(f"- Progress   : {PROGRESS_JSON}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--reset-url", type=str, default=None, help="íŠ¹ì • URLì˜ ë°ì´í„°/ì§„í–‰ìƒíƒœë¥¼ ì œê±°í•˜ê³  ì¬ì‹œì‘")
    args = parser.parse_args()
    main(reset_url=args.reset_url)
